{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset paths\n",
    "dataset_paths = os.path.join(os.getcwd(), os.path.join(os.path.join(\"dataset_1\"), \"dataset_full\"))\n",
    "dataset_paths = {\n",
    "    \"Building\": os.path.join(dataset_paths, \"Building\"),\n",
    "    \"Forest\": os.path.join(dataset_paths, \"Forest\"),\n",
    "    \"Glacier\": os.path.join(dataset_paths, \"Glacier\"),\n",
    "    \"Mountain\": os.path.join(dataset_paths, \"Mountains\"),\n",
    "    \"Sea\": os.path.join(dataset_paths, \"Sea\"),\n",
    "    \"Street\": os.path.join(dataset_paths, \"Streets\")\n",
    "}\n",
    "\n",
    "def process_image(img, target_size=(128, 128)):\n",
    "    try:\n",
    "        img = cv2.resize(img, target_size)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        eq_img = cv2.equalizeHist(gray_img)\n",
    "        return eq_img\n",
    "    except Exception as err:\n",
    "        print(f\"Error processing image: {err}\")\n",
    "        return None\n",
    "\n",
    "def load_and_process_images(dataset_paths):\n",
    "    images = []\n",
    "    targets = []\n",
    "    labels_list = list(dataset_paths.keys())\n",
    "\n",
    "    for label in labels_list:\n",
    "        label_path = dataset_paths[label]\n",
    "        label_index = labels_list.index(label)\n",
    "\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(label_path):\n",
    "            file_path = os.path.join(label_path, filename)\n",
    "            img = cv2.imread(file_path)\n",
    "\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            processed_img = process_image(img)\n",
    "            if processed_img is not None:\n",
    "                images.append(processed_img)\n",
    "                targets.append(label_index)\n",
    "\n",
    "    return np.array(images), np.array(targets)\n",
    "\n",
    "\n",
    "def extract_features(images):\n",
    "    feature_list = []\n",
    "    for img in images:\n",
    "        histogram = cv2.calcHist([img], [0], None, [256], [0, 256]).flatten()\n",
    "\n",
    "        sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5).flatten()\n",
    "        sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5).flatten()\n",
    "\n",
    "        hog_features, _ = hog(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "\n",
    "        lbp = local_binary_pattern(img, P=8, R=1, method='uniform')\n",
    "        lbp_histogram = np.histogram(lbp, bins=np.arange(0, 27), range=(0, 26))[0]\n",
    "\n",
    "        combined_features = np.hstack((histogram, sobel_x, sobel_y, hog_features, lbp_histogram))\n",
    "        feature_list.append(combined_features)\n",
    "\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "images, targets = load_and_process_images(dataset_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.2, random_state=100, stratify=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "X_train_features = extract_features(X_train)\n",
    "X_test_features = extract_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_features)\n",
    "X_test = scaler.transform(X_test_features)\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=200)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Balancing the data with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8226882745471878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       100\n",
      "           1       0.95      0.98      0.96       549\n",
      "           2       0.53      0.60      0.56       100\n",
      "           3       0.62      0.60      0.61       100\n",
      "           4       0.65      0.59      0.62       100\n",
      "           5       0.83      0.76      0.79       100\n",
      "\n",
      "    accuracy                           0.82      1049\n",
      "   macro avg       0.73      0.71      0.71      1049\n",
      "weighted avg       0.82      0.82      0.82      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions and evaluation\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8007626310772163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66       100\n",
      "           1       0.95      0.97      0.96       549\n",
      "           2       0.51      0.54      0.52       100\n",
      "           3       0.60      0.53      0.56       100\n",
      "           4       0.62      0.71      0.66       100\n",
      "           5       0.74      0.68      0.71       100\n",
      "\n",
      "    accuracy                           0.80      1049\n",
      "   macro avg       0.69      0.67      0.68      1049\n",
      "weighted avg       0.80      0.80      0.80      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8045757864632984\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.63      0.67       100\n",
      "           1       0.94      0.97      0.96       549\n",
      "           2       0.54      0.53      0.54       100\n",
      "           3       0.60      0.53      0.56       100\n",
      "           4       0.63      0.71      0.67       100\n",
      "           5       0.72      0.69      0.70       100\n",
      "\n",
      "    accuracy                           0.80      1049\n",
      "   macro avg       0.69      0.68      0.68      1049\n",
      "weighted avg       0.80      0.80      0.80      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "ensemble_model = StackingClassifier(estimators=[('rf', rf_model), ('xgb', xgb)])\n",
    "ensemble_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save models and components\n",
    "model_path = os.path.join(os.getcwd(), \"models\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model_data = {\n",
    "    'classifier': svm_model,\n",
    "    'pca': pca,\n",
    "    'scaler': scaler,\n",
    "    'label_encoder': list(dataset_paths.keys())\n",
    "}\n",
    "\n",
    "with open(os.path.join(model_path, \"models.pkl\"), 'wb') as file:\n",
    "    pickle.dump(model_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tasks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
